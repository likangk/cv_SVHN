{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "## Baseline 思路\n",
    "将不定长字符串转换为定长字符的识别问题，并使用CNN完成训练和验证，具体包括以下几个步骤：\n",
    "1. 赛事数据读取（封装为Pytorch的Dataset和DataLoder）\n",
    "2. 构建CNN模型（使用Pytorch搭建）\n",
    "3. 模型训练与验证\n",
    "4. 模型结果预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入常用的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch \n",
    "torch.manual_seed(0) \n",
    "torch.backends.cudnn.deterministic = False \n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.datasets as datasets \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤一：定义好读取图像的Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self,img_path,img_label,transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    def __getitem__(self,index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # 设置最长字符长度为五个\n",
    "        lbl = np.array(self.img_label[index],dtype=np.int)\n",
    "        lbl = list(lbl) + (5-len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤二：定义训练数据和验证数据的Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "train_path = glob.glob(r'C:\\Users\\dell\\Documents\\mchar_train\\mchar_train\\*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open(r'C:\\Users\\dell\\Documents\\mchar_train\\mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path),len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path,train_label,\n",
    "                 transforms.Compose([\n",
    "                     transforms.Resize((64,128)),\n",
    "                     transforms.RandomCrop((60,120)),\n",
    "                     transforms.ColorJitter(0.3,0.3,0.2),\n",
    "                     transforms.RandomRotation(5),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])),\n",
    "    batch_size=40,\n",
    "    shuffle=True,\n",
    "    num_workers=0,#linux设为10，windows设为0\n",
    ")\n",
    "val_path = glob.glob(r'C:\\Users\\dell\\Documents\\mchar_train\\mchar_val\\*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open(r'C:\\Users\\dell\\Documents\\mchar_train\\mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤三：定义字符分类模型，使用resnet18的模型作为特征提取模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1,self).__init__()\n",
    "        \n",
    "        model_conv =models.resnet18(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        \n",
    "        self.fc1 = nn.Linear(512,11)\n",
    "        self.fc2 = nn.Linear(512,11)\n",
    "        self.fc3 = nn.Linear(512,11)\n",
    "        self.fc4 = nn.Linear(512,11)\n",
    "        self.fc5 = nn.Linear(512,11)\n",
    "    def forword(self,img):\n",
    "        feat = self.cnn(img)\n",
    "        #print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0],-1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1,c2,c3,c4,c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤四：定义好训练，验证和预测模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,model,criterion,optimizer):\n",
    "    #切换模型为训练模型\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for i,(input,target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        c0, c1, c2, c3, c4 = model(input)\n",
    "        target = target.long()\n",
    "        loss = criterion(c0, target[:,0]) + \\\n",
    "                criterion(c1, target[:,1]) + \\\n",
    "                criterion(c2, target[:,2]) + \\\n",
    "                criterion(c3, target[:,3]) + \\\n",
    "                criterion(c4, target[:,4])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validate(val_loader,model,criterion):\n",
    "    #切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    #不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input,target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "            c0, c1, c2, c3, c4 = model(input)\n",
    "            target = target.long()\n",
    "            loss = criterion(c0,target[:,0]) + \\\n",
    "                criterion(c1,target[:,1]) + \\\n",
    "                criterion(c2,target[:,2]) + \\\n",
    "                criterion(c3,target[:,3]) + \\\n",
    "                criterion(c4,target[:,4])\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def predict(test_loader,model,tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "    \n",
    "    #TTA次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i ,(input,target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "                c0, c1, c2, c3, c4 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                    c0.data.cpu().numpy(),\n",
    "                    c1.data.cpu().numpy(),\n",
    "                    c2.data.cpu().numpy(),\n",
    "                    c3.data.cpu().numpy(),\n",
    "                    c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                    c0.data.numpy(),\n",
    "                    c1.data.numpy(),\n",
    "                    c2.data.numpy(),\n",
    "                    c3.data.numpy(),\n",
    "                    c4.data.numpy()], axis=1)\n",
    "                test_pred.append(output)\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        c0, c1, c2, c3, c4 = model(input)\n",
    "        target = target.long() #添加\n",
    "        loss = criterion(c0, target[:, 0]) + \\\n",
    "                criterion(c1, target[:, 1]) + \\\n",
    "                criterion(c2, target[:, 2]) + \\\n",
    "                criterion(c3, target[:, 3]) + \\\n",
    "                criterion(c4, target[:, 4])\n",
    "        \n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "            \n",
    "            c0, c1, c2, c3, c4 = model(input)\n",
    "            target = target.long() #添加\n",
    "            loss = criterion(c0, target[:, 0]) + \\\n",
    "                    criterion(c1, target[:, 1]) + \\\n",
    "                    criterion(c2, target[:, 2]) + \\\n",
    "                    criterion(c3, target[:, 3]) + \\\n",
    "                    criterion(c4, target[:, 4])\n",
    "            # loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "    \n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "                \n",
    "                c0, c1, c2, c3, c4 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(), \n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(), \n",
    "                        c3.data.cpu().numpy(),\n",
    "                        c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(), \n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(), \n",
    "                        c3.data.numpy(),\n",
    "                        c4.data.numpy()], axis=1)\n",
    "                \n",
    "                test_pred.append(output)\n",
    "        \n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    \n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤五：迭代训练与验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.757678031921387\n",
      "5.03209114074707\n",
      "4.2331953048706055\n",
      "3.5403788089752197\n",
      "2.3217613697052\n",
      "3.0234460830688477\n",
      "2.3495593070983887\n",
      "3.0443038940429688\n",
      "Epoch: 0, Train loss: 3.543373563448588 \t Val loss: 3.4861117715835572\n",
      "0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type SVHN_Model1. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.648951292037964\n",
      "1.6623834371566772\n",
      "2.33172607421875\n",
      "2.7873375415802\n",
      "1.6994613409042358\n",
      "1.1757111549377441\n",
      "2.03737735748291\n",
      "3.2905826568603516\n",
      "Epoch: 1, Train loss: 2.174022654533386 \t Val loss: 3.1018972883224487\n",
      "0.4254\n"
     ]
    }
   ],
   "source": [
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),0.001)\n",
    "best_loss = 1000.0\n",
    "\n",
    "use_cuda = False\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "for epoch in range(2):\n",
    "    train_loss = train(train_loader,model,criterion,optimizer)\n",
    "    val_loss = validate(val_loader,model,criterion)\n",
    "    \n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict(val_loader,model,1)\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "        val_predict_label[:, 44:55].argmax(1),\n",
    "    ]).T\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        val_label_pred.append(''.join(map(str,x[x!=10])))\n",
    "        \n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "    \n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch,train_loss,val_loss))\n",
    "    print(val_char_acc)\n",
    "    \n",
    "    #记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict, 'C:/Users/dell/Documents/mchar_train//model.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤六：对测试集样本进行预测，生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "test_path = glob.glob(r'C:\\Users\\dell\\Documents\\mchar_train\\mchar_test_a\\*.png')\n",
    "test_path.sort()\n",
    "test_label = [[1]] * len(test_path)\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=0, # win下num_works改为0,linux=10\n",
    ")\n",
    "\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "\n",
    "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1),\n",
    "    test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1),\n",
    "    test_predict_label[:, 33:44].argmax(1),\n",
    "    test_predict_label[:, 44:55].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x!=10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_submit = pd.read_csv(r'C:\\Users\\dell\\Documents\\mchar_train\\mchar_sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('C:/Users/dell/Documents/mchar_train/renset18.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
